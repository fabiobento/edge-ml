{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adaptado de [\"Classificação de Imagens\"](https://www.tensorflow.org/tutorials/images/classification?hl=pt-br) dos [tutoriais do Tensorflow](https://www.tensorflow.org/tutorials/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE7KNzPPVrVV"
      },
      "source": [
        "# Classificação de Imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiobento/edge-ml/blob/main/computer-vision/classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este tutorial mostra como classificar imagens de flores usando um modelo `tf.keras.Sequential` e carregar dados usando `tf.keras.utils.image_dataset_from_directory`. Ele demonstra os seguintes conceitos:\n",
        "\n",
        "\n",
        "* Carregamento eficiente de um conjunto de dados do disco.\n",
        "* Identificação de sobreajuste e aplicação de técnicas para atenuá-lo, incluindo aumento e eliminação de dados.\n",
        "\n",
        "Este tutorial segue um fluxo de trabalho básico de aprendizado de máquina:\n",
        "\n",
        "1. Examinar e entender os dados\n",
        "2. Criar um pipeline de entrada\n",
        "3. Criar o modelo\n",
        "4. Treinar o modelo\n",
        "5. Testar o modelo\n",
        "6. Aprimore o modelo e repita o processo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF9uvbXNVrVY"
      },
      "source": [
        "## Configuração\n",
        "\n",
        "Importe o TensorFlow e outras bibliotecas necessárias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "L1WtoaOHVrVh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZZI6lNkVrVm"
      },
      "source": [
        "## Faça o download e explore o conjunto de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPHx8-t-VrVo"
      },
      "source": [
        "Este tutorial usa um conjunto de dados com cerca de 3.700 fotos de flores. O conjunto de dados contém cinco subdiretórios, um por classe:\n",
        "\n",
        "```\n",
        "flower_photo/\n",
        "  daisy/\n",
        "  dandelion/\n",
        "  roses/\n",
        "  sunflowers/\n",
        "  tulips/\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Especificar aonde está armazenado o arquivo com as fotos compactadas\n",
        "url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "file_name = \"flower_photos.tgz\"\n",
        "\n",
        "# Baixar o arquivo compactado com as imagens do conjuntos de dados\n",
        "response = requests.get(url, stream=True)\n",
        "with open(file_name, \"wb\") as file:\n",
        "    for chunk in response.iter_content(chunk_size=1024):\n",
        "        if chunk:\n",
        "            file.write(chunk)\n",
        "\n",
        "print(f\"Download concluído: {file_name}\")\n",
        "\n",
        "# 2. Extrair o arquivo .tgz\n",
        "extract_path = os.getcwd()+'/datasets'\n",
        "with tarfile.open(file_name, \"r:gz\") as tar:\n",
        "    tar.extractall(path=extract_path)\n",
        "\n",
        "data_dir = pathlib.Path(extract_path+'/'+file_name.split('.')[0]).with_suffix('')\n",
        "print(f\"Arquivos extraídos em: {data_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpmywIlsVrVx"
      },
      "source": [
        "Após o download, você deverá ter uma cópia do conjunto de dados disponível. Há um total de 3.670 imagens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbtTDYhOHZb6"
      },
      "outputs": [],
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVmwkOSdHZ5A"
      },
      "source": [
        "Aqui estão algumas rosas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1loMlbYHeiJ"
      },
      "outputs": [],
      "source": [
        "roses = list(data_dir.glob('roses/*'))\n",
        "PIL.Image.open(str(roses[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQbZBOTLHiUP"
      },
      "outputs": [],
      "source": [
        "PIL.Image.open(str(roses[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGEqiBbRHnyI"
      },
      "source": [
        "E algumas tulipas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyQkfPGdHilw"
      },
      "outputs": [],
      "source": [
        "tulips = list(data_dir.glob('tulips/*'))\n",
        "PIL.Image.open(str(tulips[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtlhWJPAHivf"
      },
      "outputs": [],
      "source": [
        "PIL.Image.open(str(tulips[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIjgz7_JIo_m"
      },
      "source": [
        "## Load data using a Keras utility\n",
        "\n",
        "Next, load these images off disk using the helpful `tf.keras.utils.image_dataset_from_directory` utility. This will take you from a directory of images on disk to a `tf.data.Dataset` in just a couple lines of code. If you like, you can also write your own data loading code from scratch by visiting the [Load and preprocess images](../load_data/images.ipynb) tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carregar dados usando um utilitário do Keras\n",
        "\n",
        "Em seguida, carregue essas imagens usando o utilitário `tf.keras.utils.image_dataset_from_directory`.\n",
        "\n",
        "Isso o levará de um diretório de imagens no disco para um `tf.data.Dataset` em apenas algumas linhas de código."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyDNn9MbIzfT"
      },
      "source": [
        "### Crie o conjunto de dados(_dataset_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anqiK_AGI086"
      },
      "source": [
        "Defina alguns parâmetros para o carregador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "H74l2DoDI2XD"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFBhRrrEI49z"
      },
      "source": [
        "É uma boa prática usar uma divisão de validação ao desenvolver seu modelo. Use 80% das imagens para treinamento e 20% para validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIR0kRZiI_AT"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=42,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iscU3UoVJBXj"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=42,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLQULyAvJC3X"
      },
      "source": [
        "Você pode encontrar os nomes das classes no atributo `class_names` nesses conjuntos de dados. Eles correspondem aos nomes dos diretórios em ordem alfabética."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHAxkHX5JD3k"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uoVvxSLJW9m"
      },
      "source": [
        "## Visualize os dados\n",
        "\n",
        "Aqui estão as primeiras nove imagens do conjunto de dados de treinamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBmEA9c0JYes"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M6BXtXFJdW0"
      },
      "source": [
        "Você passará esses conjuntos de dados para o método `Model.fit` do Keras para treinamento mais adiante neste tutorial.\n",
        "\n",
        "Se desejar, você também pode iterar manualmente o conjunto de dados e recuperar lotes de imagens:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-MfMoenJi8s"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj4FrKxxJkoW"
      },
      "source": [
        "O `image_batch` é um tensor com a forma `(32, 180, 180, 3)`.\n",
        "- Trata-se de um lote de 32 imagens de formato `180x180x3` (a última dimensão refere-se aos canais de cores RGB).\n",
        "- O `label_batch` é um tensor da forma `(32,)`, esses são os rótulos correspondentes às 32 imagens.\n",
        "\n",
        "Você pode chamar `.numpy()` nos tensores `image_batch` e `labels_batch` para convertê-los em um `numpy.ndarray`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure o conjunto de dados para desempenho\n",
        "\n",
        "Certifique-se de usar o pré-busca com buffer(_buffered prefetching_), para que você possa obter dados do disco sem que a E/S se torne bloqueada. Esses são dois métodos importantes que você deve usar ao carregar dados:\n",
        "\n",
        "- O `Dataset.cache` mantém as imagens na memória depois que elas são carregadas do disco durante a primeira época. Isso garantirá que o conjunto de dados não se torne um gargalo durante o treinamento do modelo. Se o conjunto de dados for muito grande para caber na memória, você também poderá usar esse método para criar um cache de alto desempenho no disco.\n",
        "- O `Dataset.prefetch` sobrepõe o pré-processamento de dados e a execução do modelo durante o treinamento.\n",
        "\n",
        "Se estiver interessado, pode saber mais sobre os dois métodos, bem como sobre como armazenar dados em cache no disco, na seção *Prefetching* do guia [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance?hl=pt-br)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "nOjJSm7DKoZA"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GUnmPF4JvEf"
      },
      "source": [
        "## Padronize os dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e56VXHMWJxYT"
      },
      "source": [
        "Os valores do canal RGB estão no intervalo `[0, 255]`. Isso não é ideal para uma rede neural; em geral, você deve procurar tornar os valores de entrada pequenos.\n",
        "\n",
        "Aqui, você padronizará os valores para que fiquem no intervalo `[0, 1]` usando `tf.keras.layers.Rescaling`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "PEYxo2CTJvY9"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl4RmanbJ4g0"
      },
      "source": [
        "Há duas maneiras de usar essa camada. Você pode aplicá-la ao conjunto de dados chamando `Dataset.map`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9o9ESaJJ502"
      },
      "outputs": [],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Observe que os valores de pixel estão agora em `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWEOmRSBJ9J8"
      },
      "source": [
        "Or, you can include the layer inside your model definition, which can simplify deployment. Use the second approach here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsRk1xCwKZR4"
      },
      "source": [
        "Note: You previously resized images using the `image_size` argument of `tf.keras.utils.image_dataset_from_directory`. If you want to include the resizing logic in your model as well, you can use the `tf.keras.layers.Resizing` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Um modelo básico do Keras\n",
        "\n",
        "### Criar o modelo\n",
        "\n",
        "O modelo Keras [Sequential](https://www.tensorflow.org/guide/keras/sequential_model) consiste em três blocos de convolução (`tf.keras.layers.Conv2D`) com uma camada de pooling máximo (`tf.keras.layers.MaxPooling2D`) em cada um deles.\n",
        "\n",
        "Há uma camada totalmente conectada (`tf.keras.layers.Dense`) com 128 unidades na parte superior, que é ativada por uma função de ativação ReLU (`'relu'`).\n",
        "\n",
        "Esse modelo não foi ajustado para alta acurácia; o objetivo deste tutorial é mostrar uma abordagem padrão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR6argA1K074"
      },
      "outputs": [],
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaKFzz72Lqpg"
      },
      "source": [
        "### Compilar o modelo\n",
        "\n",
        "Para este tutorial, escolha o otimizador `tf.keras.optimizers.Adam` e a função de perda `tf.keras.losses.SparseCategoricalCrossentropy`.\n",
        "\n",
        "Para visualizar a acurácia do treinamento e da validação para cada época de treinamento, passe o argumento `metrics` para `Model.compile`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jloGNS1MLx3A"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMJ4DnuJL55A"
      },
      "source": [
        "### Resumo do modelo\n",
        "\n",
        "Visualize todas as camadas da rede usando o método `Model.summary` do Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llLYH-BXL7Xe"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiYHcbvaL9H-"
      },
      "source": [
        "### Treine o modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j30F69T4sIVN"
      },
      "source": [
        "Treine o modelo para 10 épocas com o método `Model.fit` do Keras:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fWToCqYMErH"
      },
      "outputs": [],
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyFKdQpXMJT4"
      },
      "source": [
        "## Visualize os resultados do treinamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFvOvmAmMK9w"
      },
      "source": [
        "Crie gráficos da perda e da acurácia nos conjuntos de treinamento e validação:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWnopEChMMCn"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Acurácia de Treino')\n",
        "plt.plot(epochs_range, val_acc, label='Acurácia de Validação')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Acurácia de Treino e Validação')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Perda de Treino')\n",
        "plt.plot(epochs_range, val_loss, label='Perda de Validação')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Perdas de Treino e Validação')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO_jT7HwMrEn"
      },
      "source": [
        "Os gráficos mostram que a acurácia do treinamento e a acurácia da validação estão fora de uma grande margem, e o modelo alcançou apenas cerca de 60% de acurácia no conjunto de validação.\n",
        "\n",
        "As seções do tutorial a seguir mostram como inspecionar o que deu errado e tentar aumentar o desempenho geral do modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqtyGodAMvNV"
      },
      "source": [
        "## Sobreajuste(_Overfitting_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nos gráficos acima, a acurácia do treinamento está aumentando linearmente ao longo do tempo, ao passo que a acurácia da validação fica parada em torno de 60% no processo de treinamento. Além disso, a diferença entre a acurácia do treinamento e da validação é perceptível - um sinal de [overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit).\n",
        "\n",
        "Quando há um pequeno número de exemplos de treinamento, o modelo às vezes aprende com ruídos ou detalhes indesejados dos exemplos de treinamento - a ponto de afetar negativamente o desempenho do modelo em novos exemplos. Esse fenômeno é conhecido como sobreajuste. Isso significa que o modelo terá dificuldade para generalizar em um novo conjunto de dados.\n",
        "\n",
        "Há várias maneiras de combater o ajuste excessivo no processo de treinamento. Neste tutorial, você usará *data augmentation* e adicionará *dropout* ao seu modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDMfYqwmM1C-"
      },
      "source": [
        "## Aumento de Dados(_Data augmentation_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "O overfitting geralmente ocorre quando há um pequeno número de exemplos de treinamento.\n",
        "\n",
        "O [Data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation?hl=pt-br) adota a abordagem de gerar dados de treinamento adicionais a partir dos exemplos existentes, aumentando-os com transformações aleatórias que geram imagens de aparência crível. Isso ajuda a expor o modelo a mais aspectos dos dados e a generalizar melhor.\n",
        "\n",
        "Você implementará o aumento de dados usando as seguintes camadas de pré-processamento do Keras: `tf.keras.layers.RandomFlip`, `tf.keras.layers.RandomRotation` e `tf.keras.layers.RandomZoom`. Elas podem ser incluídas em seu modelo como outras camadas e executadas na GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "9J80BAbIMs21"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN4k1dK3S6eV"
      },
      "source": [
        "Visualize alguns exemplos aumentados aplicando o aumento de dados à mesma imagem várias vezes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z90k539S838"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsjXCBLYYNs5"
      },
      "source": [
        "Na próxima etapa, você adicionará o aumento de dados ao seu modelo antes do treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dropout\n",
        "\n",
        "Outra técnica para reduzir o overfitting é introduzir a regularização [dropout](https://developers.google.com/machine-learning/glossary#dropout_regularization){:.external} na rede.\n",
        "\n",
        "Quando você aplica o dropout a uma camada, ele elimina aleatoriamente (definindo a ativação como zero) um número de unidades de saída da camada durante o processo de treinamento.\n",
        "- O dropout usa um número fracionário como seu valor de entrada, na forma de 0,1, 0,2, 0,4 etc.\n",
        "- Isso significa eliminar 10%, 20% ou 40% das unidades de saída aleatoriamente da camada aplicada.\n",
        "\n",
        "Crie uma nova rede neural com `tf.keras.layers.Dropout` antes de treiná-la usando as imagens aumentadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "2Zeg8zsqXCsm"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes, name=\"outputs\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L4nEcuqgZLbi"
      },
      "source": [
        "## Compile e treine o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "EvyAINs9ZOmJ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWLkKoKjZSoC"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWS-vvNaZDag"
      },
      "outputs": [],
      "source": [
        "epochs = 15\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize os resultados do treinamento\n",
        "\n",
        "Depois de aplicar o aumento de dados e `tf.keras.layers.Dropout`, há menos overfitting do que antes, e a acurácia do treinamento e da validação estão mais alinhadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Acurácia de Treino')\n",
        "plt.plot(epochs_range, val_acc, label='Acurácia de Validação')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Acurácia de Treino e Validação')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Perda de Treino')\n",
        "plt.plot(epochs_range, val_loss, label='Perda de Validação')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Perdas de Treino e Validação')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtv5VbaVb-3W"
      },
      "source": [
        "## Prever com base em novos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10buWpJbcCQz"
      },
      "source": [
        "Use seu modelo para classificar uma imagem que não foi incluída nos conjuntos de treinamento ou validação."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKgMZ4bDcHf7"
      },
      "source": [
        "Observação: As camadas de aumento de dados e de abandono estão inativas no momento da inferência."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC40sRITBSsQ"
      },
      "outputs": [],
      "source": [
        "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
        "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sunflower_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"Essa imagem provavelmente é uma {} com {:.2f} por cento de confiança.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")\n",
        "\n",
        "# Exibe a imagem\n",
        "# Remove a dimensão do batch para visualização\n",
        "img_array = np.squeeze(img_array, axis=0)\n",
        "\n",
        "# Plota a imagem\n",
        "plt.imshow(img_array.astype('uint8'))\n",
        "plt.title(\n",
        "    \"Essa imagem provavelmente é uma {} com {:.2f} por cento de confiança.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")\n",
        "plt.axis('off')  # Remove os eixos para melhor visualização\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "classification.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
