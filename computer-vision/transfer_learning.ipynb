{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptado de [\"Transferência de aprendizado e ajuste fino\"](https://www.tensorflow.org/tutorials/images/transfer_learning?hl=pt-br) dos [tutoriais do Tensorflow](https://www.tensorflow.org/tutorials/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRTa3Ee15WsJ"
   },
   "source": [
    "# _Transfer learning_ e _fine-tuning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/fabiobento/edge-ml/blob/main/computer-vision/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste tutorial, você aprenderá a classificar imagens de cães e gatos usando o transfer learning de uma rede pré-treinada.\n",
    "\n",
    "Um modelo pré-treinado é uma rede salva que foi previamente treinada em um grande conjunto de dados, normalmente em uma tarefa de classificação de imagens em grande escala. Você pode usar o modelo pré-treinado como está ou usar o transfer learning para personalizar esse modelo para uma determinada tarefa.\n",
    "\n",
    "A intuição por trás do transfer learning para classificação de imagens é que, se um modelo for treinado em um conjunto de dados grande e geral o suficiente, esse modelo servirá efetivamente como um modelo genérico do mundo visual. Assim, você pode aproveitar esses mapas de recursos aprendidos sem precisar começar do zero, treinando um modelo grande em um conjunto de dados grande.\n",
    "\n",
    "Neste notebook, você tentará duas maneiras de personalizar um modelo pré-treinado:\n",
    "\n",
    "1. Extração de recursos: Use as representações aprendidas por uma rede anterior para extrair recursos significativos de novas amostras. Basta adicionar um novo classificador, que será treinado do zero, sobre o modelo pré-treinado para que você possa reutilizar os mapas de recursos aprendidos anteriormente para o conjunto de dados.\n",
    "\n",
    " Não é necessário (re)treinar o modelo inteiro. A rede convolucional básica já contém recursos que são genericamente úteis para classificar imagens. No entanto, a parte final de classificação do modelo pré-treinado é específica para a tarefa de classificação original e, posteriormente, específica para o conjunto de classes no qual o modelo foi treinado.\n",
    "\n",
    "1. _Fine-tuning_: Descongelar algumas das camadas superiores de uma base de modelo congelada e treinar conjuntamente as camadas do classificador recém-adicionadas e as últimas camadas do modelo de base. Isso nos permite fazer o “ajuste fino” das representações de recursos de ordem superior no modelo de base para torná-las mais relevantes para a tarefa específica.\n",
    "\n",
    "Você seguirá o fluxo de trabalho geral de aprendizado de máquina.\n",
    "\n",
    "1. Examinar e entender os dados\n",
    "1. Crie um pipeline de entrada, neste caso usando o Keras ImageDataGenerator\n",
    "1. Compor o modelo\n",
    "   * Carregar o modelo de base pré-treinado (e pesos pré-treinados)\n",
    "   * Empilhar as camadas de classificação na parte superior\n",
    "1. Treinar o modelo\n",
    "1. Avaliar o modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:01.845465Z",
     "iopub.status.busy": "2024-08-16T03:08:01.845200Z",
     "iopub.status.idle": "2024-08-16T03:08:04.475932Z",
     "shell.execute_reply": "2024-08-16T03:08:04.475067Z"
    },
    "id": "TqOt6Sv7AsMi"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v77rlkCKW0IJ"
   },
   "source": [
    "## Preprocessamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GoKGm1duzgk"
   },
   "source": [
    "### Download dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste tutorial, você usará um conjunto de dados que contém vários milhares de imagens de cães e gatos.\n",
    "\n",
    "Faça download e extraia um arquivo zip contendo as imagens e, em seguida, crie um `tf.data.Dataset` para treinamento e validação usando o utilitário `tf.keras.utils.image_dataset_from_directory`.\n",
    "\n",
    "Você pode saber mais sobre o carregamento de imagens neste [tutorial](https://www.tensorflow.org/tutorials/load_data/images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:04.480715Z",
     "iopub.status.busy": "2024-08-16T03:08:04.480284Z",
     "iopub.status.idle": "2024-08-16T03:08:09.104737Z",
     "shell.execute_reply": "2024-08-16T03:08:09.103697Z"
    },
    "id": "ro4oYaEmxe4r"
   },
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
    "\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (160, 160)\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:09.109069Z",
     "iopub.status.busy": "2024-08-16T03:08:09.108771Z",
     "iopub.status.idle": "2024-08-16T03:08:09.179342Z",
     "shell.execute_reply": "2024-08-16T03:08:09.178599Z"
    },
    "id": "cAvtLwi7_J__"
   },
   "outputs": [],
   "source": [
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(validation_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yO1Q2JaW5sIy"
   },
   "source": [
    "Mostre as primeiras nove imagens e rótulos do conjunto de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:09.182630Z",
     "iopub.status.busy": "2024-08-16T03:08:09.182361Z",
     "iopub.status.idle": "2024-08-16T03:08:10.008164Z",
     "shell.execute_reply": "2024-08-16T03:08:10.007482Z"
    },
    "id": "K5BeQyKThC_Y"
   },
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZqCX_mpV3Mx"
   },
   "source": [
    "Como o conjunto de dados original não contém um conjunto de teste, você criará um.\n",
    "\n",
    "Para fazer isso, determine quantos lotes de dados estão disponíveis no conjunto de validação usando `tf.data.experimental.cardinality` e, em seguida, mova 20% deles para um conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:10.020320Z",
     "iopub.status.busy": "2024-08-16T03:08:10.020054Z",
     "iopub.status.idle": "2024-08-16T03:08:10.028900Z",
     "shell.execute_reply": "2024-08-16T03:08:10.028309Z"
    },
    "id": "uFFIYrTFV9RO"
   },
   "outputs": [],
   "source": [
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // 5)\n",
    "validation_dataset = validation_dataset.skip(val_batches // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:10.032077Z",
     "iopub.status.busy": "2024-08-16T03:08:10.031656Z",
     "iopub.status.idle": "2024-08-16T03:08:10.035999Z",
     "shell.execute_reply": "2024-08-16T03:08:10.035311Z"
    },
    "id": "Q9pFlFWgBKgH"
   },
   "outputs": [],
   "source": [
    "print('Número de lotes de validação: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Número de lotes de teste: %d' % tf.data.experimental.cardinality(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MakSrdd--RKg"
   },
   "source": [
    "### Configurar o conjunto de dados para desempenho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22XWC7yjkZu4"
   },
   "source": [
    "Use a pré-busca com buffer(_buffered prefetching_) para carregar imagens do disco sem que a E/S se torne bloqueada. Para saber mais sobre esse método, consulte o guia [data performance](https://www.tensorflow.org/guide/data_performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:10.039127Z",
     "iopub.status.busy": "2024-08-16T03:08:10.038728Z",
     "iopub.status.idle": "2024-08-16T03:08:10.045249Z",
     "shell.execute_reply": "2024-08-16T03:08:10.044662Z"
    },
    "id": "p3UUPdm86LNC"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYfcVwYLiR98"
   },
   "source": [
    "### Use _data augmentation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bDWc5Oad1daX"
   },
   "source": [
    "When you don't have a large image dataset, it's a good practice to artificially introduce sample diversity by applying random, yet realistic, transformations to the training images, such as rotation and horizontal flipping. This helps expose the model to different aspects of the training data and reduce [overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit). You can learn more about data augmentation in this [tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando não se tem um grande conjunto de dados de imagens, é uma boa prática introduzir artificialmente a diversidade de amostras aplicando transformações aleatórias, porém realistas, às imagens de treinamento, como rotação e inversão horizontal.\n",
    "\n",
    "Isso ajuda a expor o modelo a diferentes aspectos dos dados de treinamento e a reduzir o [overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit).\n",
    "\n",
    "Você pode saber mais sobre o aumento de dados neste [tutorial](https://www.tensorflow.org/tutorials/images/data_augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:10.048665Z",
     "iopub.status.busy": "2024-08-16T03:08:10.048431Z",
     "iopub.status.idle": "2024-08-16T03:08:10.057681Z",
     "shell.execute_reply": "2024-08-16T03:08:10.057082Z"
    },
    "id": "3P99QiMGit1A"
   },
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9SlcbhrarOO"
   },
   "source": [
    "Observação: essas camadas ficam ativas somente durante o treinamento, quando você chama `Model.fit`. Elas ficam inativas quando o modelo é usado no modo de inferência em `Model.evaluate`, `Model.predict` ou `Model.call`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mD3rE2Lm7-d"
   },
   "source": [
    "Vamos aplicar repetidamente essas camadas à mesma imagem e ver o resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:10.060950Z",
     "iopub.status.busy": "2024-08-16T03:08:10.060709Z",
     "iopub.status.idle": "2024-08-16T03:08:12.224092Z",
     "shell.execute_reply": "2024-08-16T03:08:12.223420Z"
    },
    "id": "aQullOUHkm67"
   },
   "outputs": [],
   "source": [
    "for image, _ in train_dataset.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAywKtuVn8uK"
   },
   "source": [
    "### Redimensionar valores de pixel\n",
    "\n",
    "Em breve, você fará o download do `tf.keras.applications.MobileNetV2` para usá-lo como seu modelo básico.\n",
    "\n",
    "Esse modelo espera valores de pixel em `[-1, 1]`, mas, nesse momento, os valores de pixel em suas imagens estão em `[0, 255]`. Para redimensioná-los, use o método de pré-processamento incluído no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:12.237462Z",
     "iopub.status.busy": "2024-08-16T03:08:12.237186Z",
     "iopub.status.idle": "2024-08-16T03:08:12.240599Z",
     "shell.execute_reply": "2024-08-16T03:08:12.240005Z"
    },
    "id": "cO0HM9JAQUFq"
   },
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnr81qRMzcs5"
   },
   "source": [
    "Observação: como alternativa, você pode redimensionar os valores de pixel de `[0, 255]` para `[-1, 1]` usando `tf.keras.layers.Rescaling`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:12.243654Z",
     "iopub.status.busy": "2024-08-16T03:08:12.243428Z",
     "iopub.status.idle": "2024-08-16T03:08:12.247337Z",
     "shell.execute_reply": "2024-08-16T03:08:12.246635Z"
    },
    "id": "R2NyJn4KQMux"
   },
   "outputs": [],
   "source": [
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz7qgImhTxw4"
   },
   "source": [
    "Observação: se estiver usando outros `tf.keras.applications`, verifique o documento da API para determinar se eles esperam pixels em `[-1, 1]` ou `[0, 1]`, ou use a função `preprocess_input` incluída."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crie o modelo básico a partir de convnets pré-treinadas\n",
    "Você criará o modelo básico a partir do modelo **MobileNet V2** desenvolvido no Google.\n",
    "- Ele é pré-treinado no conjunto de dados ImageNet, um grande conjunto de dados que consiste em 1,4 milhão de imagens e 1.000 classes.\n",
    "- O ImageNet é um conjunto de dados de treinamento de pesquisa com uma ampla variedade de categorias, como `jackfruit` e `syringe`.\n",
    "- Essa base de conhecimento nos ajudará a classificar gatos e cachorros em nosso conjunto de dados específico.\n",
    "\n",
    "Primeiro, você precisa escolher a camada do MobileNet V2 que usará para extração de recursos.\n",
    "- A última camada de classificação (no “topo”, já que a maioria dos diagramas de modelos de aprendizado de máquina vai de baixo para cima) não é muito útil.\n",
    "- Em vez disso, você seguirá a prática comum de depender da última camada antes da operação de _flattening_.\n",
    "- Essa camada é chamada de “camada de gargalo”.\n",
    "- Os recursos da camada de gargalo mantêm mais generalidade em comparação com a camada final/superior.\n",
    "\n",
    "Primeiro, instancie um modelo MobileNet V2 pré-carregado com pesos treinados no ImageNet.\n",
    "- Ao especificar o argumento **include_top=False**, você carrega uma rede que não inclui as camadas de classificação na parte superior, o que é ideal para a extração de recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:12.250703Z",
     "iopub.status.busy": "2024-08-16T03:08:12.250458Z",
     "iopub.status.idle": "2024-08-16T03:08:13.443647Z",
     "shell.execute_reply": "2024-08-16T03:08:13.442949Z"
    },
    "id": "19IQ2gqneqmS"
   },
   "outputs": [],
   "source": [
    "# Criar o modelo básico a partir do modelo pré-treinado MobileNet V2\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqcsxoJIEVXZ"
   },
   "source": [
    "Esse extrator de recursos converte cada imagem `160x160x3` em um bloco de recursos `5x5x1280`. Vejamos o que ele faz em um exemplo de lote de imagens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:13.447717Z",
     "iopub.status.busy": "2024-08-16T03:08:13.447417Z",
     "iopub.status.idle": "2024-08-16T03:08:14.009021Z",
     "shell.execute_reply": "2024-08-16T03:08:14.008315Z"
    },
    "id": "Y-2LJL0EEUcx"
   },
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlx56nQtfe8Y"
   },
   "source": [
    "## Extração de recursos\n",
    "Nesta etapa, você congelará a base convolucional criada na etapa anterior e a usará como um extrator de recursos. Além disso, você adiciona um classificador sobre ele e treina o classificador de nível superior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnMLieHBCwil"
   },
   "source": [
    "### Congelar a base convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fL6upiN3ekS"
   },
   "source": [
    "É importante congelar a base convolucional antes de compilar e treinar o modelo.\n",
    "\n",
    "O congelamento (definindo layer.trainable = False) impede que os pesos em uma determinada camada sejam atualizados durante o treinamento.\n",
    "\n",
    "O MobileNet V2 tem muitas camadas, portanto, definir o sinalizador `trainable` do modelo inteiro como False congelará todas elas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.012727Z",
     "iopub.status.busy": "2024-08-16T03:08:14.012482Z",
     "iopub.status.idle": "2024-08-16T03:08:14.017814Z",
     "shell.execute_reply": "2024-08-16T03:08:14.017197Z"
    },
    "id": "OTCJH4bphOeo"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsNHwpm7BeVM"
   },
   "source": [
    "### Observação importante sobre as camadas de BatchNormalization\n",
    "\n",
    "Muitos modelos contêm camadas `tf.keras.layers.BatchNormalization`. Essa camada é um caso especial e devem ser tomadas precauções no contexto do fine tuning, conforme mostrado mais adiante neste tutorial.\n",
    "\n",
    "Quando você define `layer.trainable = False`, a camada `BatchNormalization` será executada no modo de inferência e não atualizará suas estatísticas de média e variância.\n",
    "\n",
    "Quando você descongela um modelo que contém camadas de BatchNormalization para fazer o fine tuning, deve manter as camadas de BatchNormalization no modo de inferência passando `training = False` ao chamar o modelo básico. Caso contrário, as atualizações aplicadas aos pesos não treináveis destruirão o que o modelo aprendeu.\n",
    "\n",
    "Para obter mais detalhes, consulte o [Transfer learning guide](https://www.tensorflow.org/guide/keras/transfer_learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.021280Z",
     "iopub.status.busy": "2024-08-16T03:08:14.020659Z",
     "iopub.status.idle": "2024-08-16T03:08:14.169231Z",
     "shell.execute_reply": "2024-08-16T03:08:14.168671Z"
    },
    "id": "KpbzSmPkDa-N"
   },
   "outputs": [],
   "source": [
    "# Vamos dar uma olhada na arquitetura do modelo básico\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdMRM8YModbk"
   },
   "source": [
    "### Adicionar um cabeçalho de classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBc31c4tMOdH"
   },
   "source": [
    "Para gerar previsões a partir do bloco de recursos, faça a média dos valores espaciais `5x5`, usando uma camada `tf.keras.layers.GlobalAveragePooling2D` para converter os recursos em um único vetor de 1280 elementos por imagem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.175751Z",
     "iopub.status.busy": "2024-08-16T03:08:14.175506Z",
     "iopub.status.idle": "2024-08-16T03:08:14.183875Z",
     "shell.execute_reply": "2024-08-16T03:08:14.183300Z"
    },
    "id": "dLnpMF5KOALm"
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1p0OJBR6dOT"
   },
   "source": [
    "Aplique uma camada `tf.keras.layers.Dense` para converter esses recursos em uma única previsão por imagem.\n",
    "\n",
    "Você não precisa de uma função de ativação aqui porque essa previsão será tratada como um `logit` ou um valor de previsão bruto.\n",
    "\n",
    "Números positivos predizem a classe 1, números negativos predizem a classe 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.187164Z",
     "iopub.status.busy": "2024-08-16T03:08:14.186569Z",
     "iopub.status.idle": "2024-08-16T03:08:14.267135Z",
     "shell.execute_reply": "2024-08-16T03:08:14.266393Z"
    },
    "id": "Wv4afXKj6cVa"
   },
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXvz-ZkTa9b3"
   },
   "source": [
    "Crie um modelo encadeando as camadas de aumento de dados, redimensionamento, `base_model` e extrator de recursos usando a [Keras Functional API](https://www.tensorflow.org/guide/keras/functional).\n",
    "\n",
    "Conforme mencionado anteriormente, use `training=False`, pois nosso modelo contém uma camada `BatchNormalization`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.270979Z",
     "iopub.status.busy": "2024-08-16T03:08:14.270317Z",
     "iopub.status.idle": "2024-08-16T03:08:14.283674Z",
     "shell.execute_reply": "2024-08-16T03:08:14.283083Z"
    },
    "id": "DgzQX6Veb2WT"
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.287211Z",
     "iopub.status.busy": "2024-08-16T03:08:14.286594Z",
     "iopub.status.idle": "2024-08-16T03:08:14.305043Z",
     "shell.execute_reply": "2024-08-16T03:08:14.304493Z"
    },
    "id": "I8ARiyMFsgbH"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxOcmVr0ydFZ"
   },
   "source": [
    "Os mais de 8 milhões de parâmetros no MobileNet estão congelados, mas há 1,2 mil parâmetros _treináveis_ na camada Dense.\n",
    "\n",
    "Eles são divididos entre dois objetos `tf.Variable`, os pesos e as tendências."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.308542Z",
     "iopub.status.busy": "2024-08-16T03:08:14.307945Z",
     "iopub.status.idle": "2024-08-16T03:08:14.312463Z",
     "shell.execute_reply": "2024-08-16T03:08:14.311897Z"
    },
    "id": "krvBumovycVA"
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.315674Z",
     "iopub.status.busy": "2024-08-16T03:08:14.315131Z",
     "iopub.status.idle": "2024-08-16T03:08:14.691186Z",
     "shell.execute_reply": "2024-08-16T03:08:14.690264Z"
    },
    "id": "jeGk93R2ahav"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0ylJXE_kRLi"
   },
   "source": [
    "### Compilar o modelo\n",
    "\n",
    "Compile o modelo antes de treiná-lo. Como há duas classes e uma saída sigmoide, use o `BinaryAccuracy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.696557Z",
     "iopub.status.busy": "2024-08-16T03:08:14.696226Z",
     "iopub.status.idle": "2024-08-16T03:08:14.714386Z",
     "shell.execute_reply": "2024-08-16T03:08:14.713711Z"
    },
    "id": "RpR8HdyMhukJ"
   },
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxvgOYTDSWTx"
   },
   "source": [
    "### Treinar o modelo\n",
    "\n",
    "Após o treinamento de 10 épocas, você deverá ver ~96% de acurácia no conjunto de validação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:14.717767Z",
     "iopub.status.busy": "2024-08-16T03:08:14.717267Z",
     "iopub.status.idle": "2024-08-16T03:08:17.730149Z",
     "shell.execute_reply": "2024-08-16T03:08:17.729432Z"
    },
    "id": "Om4O3EESkab1"
   },
   "outputs": [],
   "source": [
    "initial_epochs = 10\n",
    "\n",
    "loss0, accuracy0 = model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:17.733900Z",
     "iopub.status.busy": "2024-08-16T03:08:17.733193Z",
     "iopub.status.idle": "2024-08-16T03:08:17.737382Z",
     "shell.execute_reply": "2024-08-16T03:08:17.736717Z"
    },
    "id": "8cYT1c48CuSd"
   },
   "outputs": [],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:17.740949Z",
     "iopub.status.busy": "2024-08-16T03:08:17.740366Z",
     "iopub.status.idle": "2024-08-16T03:08:48.325579Z",
     "shell.execute_reply": "2024-08-16T03:08:48.324887Z"
    },
    "id": "JsaRFlZ9B6WK"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hd94CKImf8vi"
   },
   "source": [
    "### Curvas de aprendizado\n",
    "\n",
    "Vamos dar uma olhada nas curvas de aprendizado da acurácia/perda de treinamento e validação ao usar o modelo básico MobileNetV2 como um extrator de recursos fixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:48.329365Z",
     "iopub.status.busy": "2024-08-16T03:08:48.329040Z",
     "iopub.status.idle": "2024-08-16T03:08:48.650127Z",
     "shell.execute_reply": "2024-08-16T03:08:48.649365Z"
    },
    "id": "53OTCh3jnbwV"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Acurácia de Treino')\n",
    "plt.plot(val_acc, label='Acurácia de Validação')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Acurácias de Treino e Validação')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Perda de Treino')\n",
    "plt.plot(val_loss, label='Perda de Validação')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Entropia Cruzada')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Perdas de Treino e Validação')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observação: Se você estiver se perguntando por que as métricas de validação são claramente melhores do que as métricas de treinamento, o principal fator é que camadas como `tf.keras.layers.BatchNormalization` e `tf.keras.layers.Dropout` afetam a acurácia durante o treinamento. Elas são desativadas ao calcular a perda de validação.\n",
    "\n",
    "Em menor escala, isso também ocorre porque as métricas de treinamento relatam a média de uma época, enquanto as métricas de validação são avaliadas após a época, de modo que as métricas de validação veem um modelo que treinou um pouco mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning\n",
    "\n",
    "No experimento de extração de recursos, você estava treinando apenas algumas camadas sobre um modelo básico do MobileNetV2.\n",
    "* Os pesos da rede pré-treinada **não** foram atualizados durante o treinamento.\n",
    "\n",
    "Uma maneira de aumentar ainda mais o desempenho é treinar (ou “ajustar”) os pesos das camadas superiores do modelo pré-treinado juntamente com o treinamento do classificador que você adicionou.\n",
    "* O processo de treinamento forçará os pesos a serem ajustados de mapas de recursos genéricos para recursos associados especificamente ao conjunto de dados.\n",
    "\n",
    "\n",
    "Observação: isso só deve ser tentado depois que você tiver treinado o classificador de nível superior com o modelo pré-treinado definido como não treinável.\n",
    "* Se você adicionar um classificador inicializado aleatoriamente em cima de um modelo pré-treinado e tentar treinar todas as camadas em conjunto, a magnitude das atualizações de gradiente será muito grande (devido aos pesos aleatórios do classificador) e o modelo pré-treinado esquecerá o que aprendeu.\n",
    "\n",
    "Além disso, você deve tentar fazer o Fine tuning de um pequeno número de camadas superiores em vez de todo o modelo MobileNet.\n",
    "* Na maioria das redes convolucionais, quanto mais alta for uma camada, mais especializada ela será.\n",
    "* As primeiras camadas aprendem recursos muito simples e genéricos que se aplicam a quase todos os tipos de imagens.\n",
    "* À medida que você sobe de nível, os recursos são cada vez mais específicos para o conjunto de dados no qual o modelo foi treinado.\n",
    "* O objetivo do Fine tuning é adaptar esses recursos especializados para que funcionem com o novo conjunto de dados, em vez de substituir o aprendizado genérico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPXnzUK0QonF"
   },
   "source": [
    "### Descongelar as camadas superiores do modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rfxv_ifotQak"
   },
   "source": [
    "Tudo o que você precisa fazer é descongelar o `base_model` e definir as camadas inferiores como não treináveis.\n",
    "\n",
    "Em seguida, você deve recompilar o modelo (necessário para que essas alterações tenham efeito) e retomar o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:48.654224Z",
     "iopub.status.busy": "2024-08-16T03:08:48.653952Z",
     "iopub.status.idle": "2024-08-16T03:08:48.659567Z",
     "shell.execute_reply": "2024-08-16T03:08:48.658923Z"
    },
    "id": "4nzcagVitLQm"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:48.662865Z",
     "iopub.status.busy": "2024-08-16T03:08:48.662310Z",
     "iopub.status.idle": "2024-08-16T03:08:48.667601Z",
     "shell.execute_reply": "2024-08-16T03:08:48.667022Z"
    },
    "id": "-4HgVAacRs5v"
   },
   "outputs": [],
   "source": [
    "# Vamos dar uma olhada para ver quantas camadas existem no modelo básico\n",
    "print(\"Número de camadas no modelo básico: \", len(base_model.layers))\n",
    "\n",
    "# Fine tuning a partir dessa camada\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Congelar todas as camadas antes da camada `fine_tune_at\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Uk1dgsxT0IS"
   },
   "source": [
    "### Compilar o modelo\n",
    "\n",
    "Como você está treinando um modelo muito maior e deseja readaptar os pesos pré-treinados, é importante usar uma taxa de aprendizado menor nesse estágio. Caso contrário, seu modelo poderá se ajustar muito rapidamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:48.671073Z",
     "iopub.status.busy": "2024-08-16T03:08:48.670502Z",
     "iopub.status.idle": "2024-08-16T03:08:48.681011Z",
     "shell.execute_reply": "2024-08-16T03:08:48.680438Z"
    },
    "id": "NtUnaz0WUDva"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:48.684009Z",
     "iopub.status.busy": "2024-08-16T03:08:48.683788Z",
     "iopub.status.idle": "2024-08-16T03:08:48.702906Z",
     "shell.execute_reply": "2024-08-16T03:08:48.702350Z"
    },
    "id": "WwBWy7J2kZvA"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:48.705624Z",
     "iopub.status.busy": "2024-08-16T03:08:48.705391Z",
     "iopub.status.idle": "2024-08-16T03:08:48.709946Z",
     "shell.execute_reply": "2024-08-16T03:08:48.709308Z"
    },
    "id": "bNXelbMQtonr"
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G5O4jd6TuAG"
   },
   "source": [
    "### Continuar o treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0foWUN-yDLo_"
   },
   "source": [
    "Se você treinou para a convergência mais cedo, essa etapa aumentará sua acurácia em alguns pontos percentuais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:08:48.713033Z",
     "iopub.status.busy": "2024-08-16T03:08:48.712815Z",
     "iopub.status.idle": "2024-08-16T03:09:37.627598Z",
     "shell.execute_reply": "2024-08-16T03:09:37.626739Z"
    },
    "id": "ECQLkAsFTlun"
   },
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=len(history.epoch),\n",
    "                         validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TfXEmsxQf6eP"
   },
   "source": [
    "Vamos dar uma olhada nas curvas de aprendizado da acurácia/perda de treinamento e validação ao fazer o fine tuningdas últimas camadas do modelo básico do MobileNetV2 e treinar o classificador sobre ele.\n",
    "* A perda de validação é muito maior do que a perda de treinamento, portanto, pode haver um overfitting.\n",
    "\n",
    "O overfitting também pode etar ocorrendo pois o novo conjunto de treinamento é relativamente pequeno e semelhante aos conjuntos de dados originais do MobileNetV2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNtfNZKlInGT"
   },
   "source": [
    "Após o fine tuning, o modelo quase atinge 98% de acurácia no conjunto de validação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:09:37.632265Z",
     "iopub.status.busy": "2024-08-16T03:09:37.631586Z",
     "iopub.status.idle": "2024-08-16T03:09:37.636077Z",
     "shell.execute_reply": "2024-08-16T03:09:37.635140Z"
    },
    "id": "PpA8PlpQKygw"
   },
   "outputs": [],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:09:37.639447Z",
     "iopub.status.busy": "2024-08-16T03:09:37.638948Z",
     "iopub.status.idle": "2024-08-16T03:09:37.920546Z",
     "shell.execute_reply": "2024-08-16T03:09:37.919941Z"
    },
    "id": "chW103JUItdk"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Acurácia de Treino')\n",
    "plt.plot(val_acc, label='Acurácia de Validação')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Início do fine tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Acurácia de Validação e Treino')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Perda de Treino')\n",
    "plt.plot(val_loss, label='Perda de Validação')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Início do fine tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Perda de Treino e Validação')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6cWgjgfrsn5"
   },
   "source": [
    "### Avaliação e previsão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSXH7PRMxOi5"
   },
   "source": [
    "Por fim, você pode verificar o desempenho do modelo em novos dados usando o conjunto de testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:09:37.924803Z",
     "iopub.status.busy": "2024-08-16T03:09:37.924151Z",
     "iopub.status.idle": "2024-08-16T03:09:38.132165Z",
     "shell.execute_reply": "2024-08-16T03:09:38.131522Z"
    },
    "id": "2KyNhagHwfar"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UjS5ukZfOcR"
   },
   "source": [
    "E agora você está pronto para usar esse modelo para prever se o seu animal de estimação é um gato ou um cachorro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-16T03:09:38.136057Z",
     "iopub.status.busy": "2024-08-16T03:09:38.135203Z",
     "iopub.status.idle": "2024-08-16T03:09:40.807143Z",
     "shell.execute_reply": "2024-08-16T03:09:40.806469Z"
    },
    "id": "RUNoQNgtfNgt"
   },
   "outputs": [],
   "source": [
    "# Recuperar um lote de imagens do conjunto de teste\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "  ax = plt.subplot(3, 3, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo\n",
    "\n",
    "* Uso de um modelo pré-treinado para extração de recursos**:  Ao trabalhar com um conjunto de dados pequeno, é uma prática comum aproveitar os recursos aprendidos por um modelo treinado em um conjunto de dados maior no mesmo domínio. Isso é feito instanciando o modelo pré-treinado e adicionando um classificador totalmente conectado por cima. O modelo pré-treinado é “congelado” e somente os pesos do classificador são atualizados durante o treinamento.\n",
    "Nesse caso, a base convolucional extraiu todos os recursos associados a cada imagem e você acabou de treinar um classificador que determina a classe da imagem com base nesse conjunto de recursos extraídos.\n",
    "\n",
    "* **Fine tuning de um modelo pré-treinado**: Para melhorar ainda mais o desempenho, é possível redirecionar as camadas de nível superior dos modelos pré-treinados para o novo conjunto de dados por meio do fine tuning.\n",
    "Nesse caso, você ajustou os pesos de modo que o modelo aprendesse recursos de alto nível específicos do conjunto de dados. Essa técnica geralmente é recomendada quando o conjunto de dados de treinamento é grande e muito semelhante ao conjunto de dados original no qual o modelo pré-treinado foi treinado.\n",
    "\n",
    "Para saber mais, visite o [Transfer learning guide](https://www.tensorflow.org/guide/keras/transfer_learning).\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "transfer_learning.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
